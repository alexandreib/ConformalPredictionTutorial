{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1YYydyQNswp_nkxQHC8qqViMW1T_N_Iya",
      "authorship_tag": "ABX9TyM9OCZV3EdZ2MYeY9AG3nDz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandreib/ConformalPredictionTutorial/blob/main/JS_%7C_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # !export KAGGLE_CONFIG_DIR=/content/drive/MyDrive/kaggle.json\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "# !kaggle competitions  download -c 'jane-street-real-time-market-data-forecasting' -p '/content/drive/MyDrive/kaggle/'\n",
        "# !unzip /content/drive/MyDrive/kaggle/jane-street-real-time-market-data-forecasting.zip -d /content/drive/MyDrive/kaggle/"
      ],
      "metadata": {
        "id": "ogQ5L-2qGQrC"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna==4.0.0, catboost==1.2.7, lightgbm==4.2.0, xgboost==2.0.3, tensorflow==2.16.1, scikit-learn==1.2.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQVc3cChWmFS",
        "outputId": "8e311ddc-1253-4c57-ec64-68f5b2e0ddb9"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna==4.0.0 in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: catboost==1.2.7 in /usr/local/lib/python3.10/dist-packages (1.2.7)\n",
            "Requirement already satisfied: lightgbm==4.2.0 in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: xgboost==2.0.3 in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: tensorflow==2.16.1 in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna==4.0.0) (1.13.3)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna==4.0.0) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna==4.0.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna==4.0.0) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna==4.0.0) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna==4.0.0) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna==4.0.0) (6.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost==1.2.7) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost==1.2.7) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost==1.2.7) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost==1.2.7) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost==1.2.7) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost==1.2.7) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.37.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (3.5.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna==4.0.0) (1.3.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost==1.2.7) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost==1.2.7) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost==1.2.7) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna==4.0.0) (3.1.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost==1.2.7) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost==1.2.7) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost==1.2.7) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost==1.2.7) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost==1.2.7) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost==1.2.7) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost==1.2.7) (9.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc,os, sys, warnings, ctypes, re, joblib, copy, json, collections, abc, tqdm, multiprocessing, random\n",
        "libc = ctypes.CDLL('libc.so.6');\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import optuna\n",
        "from optuna.visualization import (plot_optimization_history,plot_param_importances,plot_parallel_coordinate)\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "import lightgbm, catboost, tensorflow, xgboost\n",
        "print('Optuna Version',optuna.__version__)\n",
        "print('LightGBM Version',lightgbm.__version__)\n",
        "print('CatBoost Version',catboost.__version__)\n",
        "print('XGBoost Version',xgboost.__version__)\n",
        "print('TF Version',tensorflow.__version__)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GroupKFold, StratifiedKFold, StratifiedGroupKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
        "\n",
        "def is_interactive():\n",
        "    return False #True False\n",
        "\n",
        "def is_kaggle_gpu_enabled():\n",
        "    from tensorflow.python.client import device_lib # when only CPU is enabled the list shows two CPU entries, otherwise there are more, listing GPU as well\n",
        "    return len(device_lib.list_local_devices()) > 2\n",
        "\n",
        "def in_colab():\n",
        "    return True if 'google.colab' in str(get_ipython()) else False\n",
        "\n",
        "if in_colab():\n",
        "    from google.colab import output\n",
        "    output.no_vertical_scroll()\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "else :\n",
        "    import kaggle_evaluation.jane_street_inference_server\n",
        "    def is_interactive():\n",
        "        return 'runtime' in get_ipython().config.IPKernelApp.connection_file\n",
        "\n",
        "print('in_colab?', in_colab())\n",
        "print('is_kaggle_gpu_enabled?', is_kaggle_gpu_enabled())\n",
        "print('Interactive?', is_interactive())\n",
        "\n",
        "class dotdict(collections.defaultdict):\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "    def __str__(self):\n",
        "        return str(' | '.join([f\"{key}: {value}\" for key, value in self.items()]))\n",
        "    def __repr__(self):\n",
        "        return str(' | '.join([f\"{key}: {value}\" for key, value in self.items()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "xqDt4xeOGXkT",
        "outputId": "561266ab-fe45-49b4-d690-2bd0e498b588"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optuna Version 4.0.0\n",
            "LightGBM Version 4.2.0\n",
            "CatBoost Version 1.2.7\n",
            "XGBoost Version 2.0.3\n",
            "TF Version 2.16.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "window[\"aee22a78-8fa5-11ef-a62b-0242ac1c000c\"] = google.colab.output.setIframeHeight(-1, true, {\"interactive\": true, \"maxHeight\": 99999});\n",
              "//# sourceURL=js_bea153d26c"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "in_colab? True\n",
            "is_kaggle_gpu_enabled? False\n",
            "Interactive? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = dotdict(dict)\n",
        "#\n",
        "CFG.l_models = ['catboost', 'lgbm', 'xgboost', 'nn'] #catboost, lgbm, xgboost, nn\n",
        "CFG.fold_name = 'time_serie_split' #time_serie_split , add blocked_time_serie_split\n",
        "CFG.fold_n = 5 if not is_interactive() else 2\n",
        "CFG.fold_train_test_split = 0.8\n",
        "CFG.l_optuna = []\n",
        "CFG.device = 'gpu' if is_kaggle_gpu_enabled() else 'cpu'\n",
        "#\n",
        "CFG.drop =['date_id','time_id',\n",
        "            #'partition_id',\n",
        "            #'responder_0','responder_1','responder_2','responder_3','responder_4','responder_5',  'responder_7', 'responder_8',\n",
        "            #'weight', 'responder_6',\n",
        "          ]\n",
        "CFG.categoricals = ['symbol_id']\n",
        "#\n",
        "CFG.cols_onehot = []\n",
        "# Models Parameters\n",
        "CFG.lgbm = dotdict(dict)\n",
        "CFG.lgbm.objective = 'rmse'\n",
        "CFG.lgbm.verbose = -1\n",
        "CFG.lgbm.random_seed = 42\n",
        "CFG.lgbm.num_trees = 30_000 if not is_interactive() else 5 #num_iteration, n_iter, num_tree, num_trees, num_round, num_rounds, nrounds, num_boost_round, n_estimators, max_iter\n",
        "CFG.lgbm.learning_rate = 0.03\n",
        "CFG.lgbm.max_depth = 12\n",
        "CFG.lgbm.min_data_in_leaf = 25\n",
        "CFG.lgbm.num_leaves = 64\n",
        "CFG.lgbm.subsample = 1\n",
        "CFG.lgbm.reg_lambda = 0.0005\n",
        "\n",
        "CFG.lgbm.device = CFG.device.lower()\n",
        "CFG.lgbm.gpu_use_dp = True if CFG.device.lower() == 'gpu' else False\n",
        "CFG.lgbm.metric  = 'rmse'\n",
        "CFG.lgbm.eval_metric = 'rmse'\n",
        "CFG.lgbm.extra_trees = True\n",
        "CFG.lgbm.colsample_bytree = 0.8\n",
        "CFG.lgbm.subsample_freq = 1\n",
        "CFG.lgbm.early_stopping_rounds = 100\n",
        "#\n",
        "CFG.catboost = dotdict(dict)\n",
        "CFG.catboost.objective = 'RMSE'\n",
        "CFG.catboost.verbose = -1\n",
        "CFG.catboost.random_seed = 42\n",
        "CFG.catboost.num_trees = 30_000 if not is_interactive() else 5 # num_boost_round, n_estimators, num_trees\n",
        "CFG.catboost.learning_rate = 0.03\n",
        "CFG.catboost.max_depth = 12\n",
        "CFG.catboost.min_data_in_leaf = 25\n",
        "# CFG.catboost.num_leaves = 64\n",
        "# CFG.catboost.subsample = 1 # or add bootstrap_type='Poisson'\n",
        "CFG.catboost.reg_lambda = 0.0005\n",
        "\n",
        "CFG.catboost.task_type = CFG.device.upper()\n",
        "CFG.catboost.eval_metric = 'RMSE'\n",
        "if CFG.device.lower() == 'cpu' : CFG.catboost.colsample_bylevel = 0.8\n",
        "CFG.catboost.random_strength = 0.01\n",
        "# CFG.catboost.grow_policy = 'Lossguide'#  default SymmetricTree' ## Needed for Num_leaves parameter\n",
        "CFG.catboost.early_stopping_rounds = 100\n",
        "#\n",
        "CFG.xgboost = dotdict(dict)\n",
        "CFG.xgboost.objective = 'reg:squarederror'\n",
        "CFG.xgboost.verbosity = 1\n",
        "CFG.xgboost.seed = 42\n",
        "CFG.xgboost.n_estimators = 30_000 if not is_interactive() else 5 # num_boost_round, n_estimators, num_trees\n",
        "CFG.xgboost.learning_rate = 0.03\n",
        "CFG.xgboost.max_depth = 12\n",
        "CFG.xgboost.subsample = 1\n",
        "CFG.xgboost.colsample_bylevel = 0.8\n",
        "CFG.xgboost.reg_lambda = 0.0005\n",
        "CFG.xgboost.device = CFG.device.lower()\n",
        "CFG.xgboost.early_stopping_rounds = 100\n",
        "CFG.xgboost.enable_categorical = True if len(CFG.categoricals) > 0 else False\n",
        "#\n",
        "CFG.nn = dotdict(dict)\n",
        "CFG.nn.metrics = [tensorflow.keras.metrics.RootMeanSquaredError()]\n",
        "CFG.nn.epochs = 150 if not is_interactive() else 1\n",
        "CFG.nn.lr = 0.01\n",
        "CFG.nn.lr_start = 1e-5\n",
        "CFG.nn.lr_max = 1e-2\n",
        "CFG.nn.lr_rampup = 2\n",
        "CFG.nn.lr_sustain = 1\n",
        "CFG.nn.lr_decay = 0.7\n",
        "# Flow Parameters\n",
        "CFG.load = False\n",
        "CFG.load_path = ''\n",
        "CFG.l_permutation_importance = []\n",
        "CFG.post_processing = False\n",
        "CFG.data_path = '/kaggle/input/jane-street-real-time-market-data-forecasting/'\n",
        "CFG.save_path = '/kaggle/working/'\n",
        "if in_colab(): CFG.data_path = '/content/drive/MyDrive/kaggle/'\n",
        "if in_colab(): CFG.save_path = '/content/drive/MyDrive/Colab Save/'\n",
        "CFG.date_min = 600 if not is_interactive() else 1685\n",
        "CFG.date_max =  1600 if not is_interactive() else 1695 #1699\n",
        "CFG.col_target = 'responder_6'\n",
        "CFG.col_weight = 'weight'# None or column name : 'weight'\n",
        "CFG.weights = [1/len(CFG.l_models) for x in CFG.l_models]\n",
        "#\n",
        "# CFG = json.load(open(CFG.load_path + '/CFG.json', 'r'))\n",
        "json.dump(CFG, open(CFG.save_path + 'CFG.json', 'w'))\n",
        "\n",
        "if not is_interactive():\n",
        "    for key, value in CFG.items() :\n",
        "        print(f'{key} : {value}')"
      ],
      "metadata": {
        "id": "8dbXAGvUGYlj"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test = pl.scan_parquet(CFG.data_path + \"test.parquet\").collect()\n",
        "# test"
      ],
      "metadata": {
        "id": "jdBLrLuZzZGe"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pl.scan_parquet(CFG.data_path + \"train.parquet\").filter((pl.col(\"date_id\") >= CFG.date_min) & (pl.col(\"date_id\") <= CFG.date_max)\n",
        "                                                                ).select(['date_id', 'time_id', 'symbol_id', 'weight'] + [f'feature_{x:02d}' for x in range(79)] + [CFG.col_target]).collect()\n",
        "print(train)\n",
        "train_date_id_min = train['date_id'].min()\n",
        "train_date_id_max = train['date_id'].max()\n",
        "\n",
        "lags_all = pl.scan_parquet(CFG.data_path + \"train.parquet\").filter((pl.col(\"date_id\") >= CFG.date_min - 1) & (pl.col(\"date_id\") <= CFG.date_max - 1)\n",
        "                                                                ).select(['date_id','time_id','symbol_id'] + [f'responder_{x}' for x in range(9)]).collect()\n",
        "lags_all = lags_all.with_columns(pl.col('date_id') + 1)\n",
        "lags_all = lags_all.rename({f'responder_{x}': f'responder_{x}_lag_1' for x in range(9)})\n",
        "\n",
        "lags_all_date_id_min = lags_all['date_id'].min()\n",
        "lags_all_date_id_max = lags_all['date_id'].max()\n",
        "print(lags_all)\n",
        "\n",
        "print(train_date_id_min, train_date_id_max)\n",
        "print(lags_all_date_id_min, lags_all_date_id_max)\n",
        "\n",
        "lags = pl.read_parquet(CFG.data_path + 'lags.parquet')\n",
        "print(lags)\n",
        "gc.collect()\n",
        "\n",
        "lags_all = pl.concat([lags , lags_all])\n",
        "lags_all = lags_all.unique(['date_id','time_id','symbol_id'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ94tnGZGyPR",
        "outputId": "a4f36318-2a00-4a6e-9df0-2385f76b8497"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (415_272, 84)\n",
            "┌─────────┬─────────┬───────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
            "│ date_id ┆ time_id ┆ symbol_id ┆ weight   ┆ … ┆ feature_76 ┆ feature_77 ┆ feature_78 ┆ responder_ │\n",
            "│ ---     ┆ ---     ┆ ---       ┆ ---      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ 6          │\n",
            "│ i16     ┆ i16     ┆ i8        ┆ f32      ┆   ┆ f32        ┆ f32        ┆ f32        ┆ ---        │\n",
            "│         ┆         ┆           ┆          ┆   ┆            ┆            ┆            ┆ f32        │\n",
            "╞═════════╪═════════╪═══════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
            "│ 1685    ┆ 0       ┆ 0         ┆ 2.919065 ┆ … ┆ 0.939474   ┆ 0.005379   ┆ 0.047556   ┆ -1.72867   │\n",
            "│ 1685    ┆ 0       ┆ 1         ┆ 1.948649 ┆ … ┆ 2.384886   ┆ 4.872888   ┆ 3.311003   ┆ 0.093044   │\n",
            "│ 1685    ┆ 0       ┆ 2         ┆ 2.780853 ┆ … ┆ 0.347198   ┆ -0.103803  ┆ -0.078908  ┆ 3.495541   │\n",
            "│ 1685    ┆ 0       ┆ 3         ┆ 2.010021 ┆ … ┆ 2.970487   ┆ 2.383555   ┆ 3.969409   ┆ 0.01133    │\n",
            "│ 1685    ┆ 0       ┆ 4         ┆ 2.540308 ┆ … ┆ 7.494794   ┆ 12.401582  ┆ 10.208351  ┆ -0.003983  │\n",
            "│ …       ┆ …       ┆ …         ┆ …        ┆ … ┆ …          ┆ …          ┆ …          ┆ …          │\n",
            "│ 1695    ┆ 967     ┆ 34        ┆ 3.37873  ┆ … ┆ -0.230316  ┆ -0.242966  ┆ -0.365427  ┆ -0.444261  │\n",
            "│ 1695    ┆ 967     ┆ 35        ┆ 1.064318 ┆ … ┆ 2.072674   ┆ 0.344164   ┆ 0.160383   ┆ -0.256141  │\n",
            "│ 1695    ┆ 967     ┆ 36        ┆ 0.986251 ┆ … ┆ -0.255297  ┆ -0.167228  ┆ -0.269613  ┆ 0.115358   │\n",
            "│ 1695    ┆ 967     ┆ 37        ┆ 1.438966 ┆ … ┆ 0.083584   ┆ 0.107935   ┆ -0.084553  ┆ 0.287156   │\n",
            "│ 1695    ┆ 967     ┆ 38        ┆ 3.231904 ┆ … ┆ -0.083243  ┆ -0.274522  ┆ -0.328853  ┆ -0.177782  │\n",
            "└─────────┴─────────┴───────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘\n",
            "shape: (415_272, 12)\n",
            "┌─────────┬─────────┬───────────┬────────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
            "│ date_id ┆ time_id ┆ symbol_id ┆ responder_ ┆ … ┆ responder_ ┆ responder_ ┆ responder ┆ responder │\n",
            "│ ---     ┆ ---     ┆ ---       ┆ 0_lag_1    ┆   ┆ 5_lag_1    ┆ 6_lag_1    ┆ _7_lag_1  ┆ _8_lag_1  │\n",
            "│ i16     ┆ i16     ┆ i8        ┆ ---        ┆   ┆ ---        ┆ ---        ┆ ---       ┆ ---       │\n",
            "│         ┆         ┆           ┆ f32        ┆   ┆ f32        ┆ f32        ┆ f32       ┆ f32       │\n",
            "╞═════════╪═════════╪═══════════╪════════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
            "│ 1685    ┆ 0       ┆ 0         ┆ -0.824719  ┆ … ┆ -0.236959  ┆ 1.858875   ┆ -0.225995 ┆ -0.354768 │\n",
            "│ 1685    ┆ 0       ┆ 1         ┆ -0.508133  ┆ … ┆ 0.250659   ┆ 4.015657   ┆ 3.910563  ┆ 0.353908  │\n",
            "│ 1685    ┆ 0       ┆ 2         ┆ -0.293465  ┆ … ┆ -0.133503  ┆ -1.222935  ┆ -1.226747 ┆ 0.22614   │\n",
            "│ 1685    ┆ 0       ┆ 3         ┆ -0.238518  ┆ … ┆ 0.677583   ┆ -0.923358  ┆ -1.062452 ┆ 0.983229  │\n",
            "│ 1685    ┆ 0       ┆ 4         ┆ 0.355719   ┆ … ┆ 0.55583    ┆ 0.315641   ┆ 0.252127  ┆ 1.003852  │\n",
            "│ …       ┆ …       ┆ …         ┆ …          ┆ … ┆ …          ┆ …          ┆ …         ┆ …         │\n",
            "│ 1695    ┆ 967     ┆ 34        ┆ -0.35588   ┆ … ┆ 0.084726   ┆ -0.168294  ┆ -0.031814 ┆ -0.186708 │\n",
            "│ 1695    ┆ 967     ┆ 35        ┆ -0.509757  ┆ … ┆ 0.318706   ┆ -0.065351  ┆ 0.003023  ┆ -0.089382 │\n",
            "│ 1695    ┆ 967     ┆ 36        ┆ 1.294062   ┆ … ┆ 0.630714   ┆ 0.008525   ┆ 0.028673  ┆ 0.008673  │\n",
            "│ 1695    ┆ 967     ┆ 37        ┆ -1.166686  ┆ … ┆ -0.198245  ┆ 0.052388   ┆ 0.0384    ┆ 0.066958  │\n",
            "│ 1695    ┆ 967     ┆ 38        ┆ 0.133737   ┆ … ┆ 0.187368   ┆ -0.050486  ┆ -0.001358 ┆ -0.151371 │\n",
            "└─────────┴─────────┴───────────┴────────────┴───┴────────────┴────────────┴───────────┴───────────┘\n",
            "1685 1695\n",
            "1685 1695\n",
            "shape: (39, 12)\n",
            "┌─────────┬─────────┬───────────┬────────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
            "│ date_id ┆ time_id ┆ symbol_id ┆ responder_ ┆ … ┆ responder_ ┆ responder_ ┆ responder ┆ responder │\n",
            "│ ---     ┆ ---     ┆ ---       ┆ 0_lag_1    ┆   ┆ 5_lag_1    ┆ 6_lag_1    ┆ _7_lag_1  ┆ _8_lag_1  │\n",
            "│ i16     ┆ i16     ┆ i8        ┆ ---        ┆   ┆ ---        ┆ ---        ┆ ---       ┆ ---       │\n",
            "│         ┆         ┆           ┆ f32        ┆   ┆ f32        ┆ f32        ┆ f32       ┆ f32       │\n",
            "╞═════════╪═════════╪═══════════╪════════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
            "│ 0       ┆ 0       ┆ 0         ┆ -0.442215  ┆ … ┆ -0.036595  ┆ -1.305746  ┆ -0.795677 ┆ -0.143724 │\n",
            "│ 0       ┆ 0       ┆ 1         ┆ -0.651829  ┆ … ┆ -0.615652  ┆ -1.162801  ┆ -1.205924 ┆ -1.245934 │\n",
            "│ 0       ┆ 0       ┆ 2         ┆ -0.656373  ┆ … ┆ -0.378265  ┆ -1.57429   ┆ -1.863071 ┆ -0.027343 │\n",
            "│ 0       ┆ 0       ┆ 3         ┆ -0.188186  ┆ … ┆ -0.054984  ┆ 0.329152   ┆ -0.965471 ┆ 0.576635  │\n",
            "│ 0       ┆ 0       ┆ 4         ┆ -0.257462  ┆ … ┆ -0.597093  ┆ 0.219856   ┆ -0.276356 ┆ -0.90479  │\n",
            "│ …       ┆ …       ┆ …         ┆ …          ┆ … ┆ …          ┆ …          ┆ …         ┆ …         │\n",
            "│ 0       ┆ 0       ┆ 34        ┆ -0.185392  ┆ … ┆ -0.443875  ┆ -0.556474  ┆ -1.122211 ┆ -0.884185 │\n",
            "│ 0       ┆ 0       ┆ 35        ┆ -0.308923  ┆ … ┆ 0.424937   ┆ 0.518839   ┆ -0.687369 ┆ 1.440577  │\n",
            "│ 0       ┆ 0       ┆ 36        ┆ -0.074661  ┆ … ┆ -1.601274  ┆ -3.216254  ┆ -1.249338 ┆ -2.868875 │\n",
            "│ 0       ┆ 0       ┆ 37        ┆ -0.658366  ┆ … ┆ -1.562932  ┆ -0.506418  ┆ -1.355508 ┆ -2.630985 │\n",
            "│ 0       ┆ 0       ┆ 38        ┆ 0.572666   ┆ … ┆ -0.501347  ┆ -0.169114  ┆ 0.457801  ┆ -0.136777 │\n",
            "└─────────┴─────────┴───────────┴────────────┴───┴────────────┴────────────┴───────────┴───────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def reduce_memory_usage_pl(df):\n",
        "#     print(f\"Memory usage of dataframe is {round(df.estimated_size('mb'), 2)} MB\")\n",
        "#     Numeric_Int_types = [pl.Int8,pl.Int16,pl.Int32,pl.Int64]\n",
        "#     Numeric_Float_types = [pl.Float32,pl.Float64]\n",
        "#     for col in df.columns:\n",
        "#         col_type = df[col].dtype\n",
        "#         c_min = df[col].min()\n",
        "#         c_max = df[col].max()\n",
        "#         if col_type in Numeric_Int_types:\n",
        "#             if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "#                 df = df.with_columns(df[col].cast(pl.Int8))\n",
        "#             elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "#                 df = df.with_columns(df[col].cast(pl.Int16))\n",
        "#             elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "#                 df = df.with_columns(df[col].cast(pl.Int32))\n",
        "#             elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "#                 df = df.with_columns(df[col].cast(pl.Int64))\n",
        "#         elif col_type in Numeric_Float_types:\n",
        "#             if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "#                 df = df.with_columns(df[col].cast(pl.Float32))\n",
        "#             else :\n",
        "#                 pass\n",
        "#         elif col_type == pl.Utf8:\n",
        "#             df = df.with_columns(df[col].cast(pl.Categorical))\n",
        "#         else:\n",
        "#             pass\n",
        "#     print(f\"Memory usage of dataframe became {round(df.estimated_size('mb'), 2)} MB\")\n",
        "#     return df\n",
        "\n",
        "# train = reduce_memory_usage_pl(train)"
      ],
      "metadata": {
        "id": "Wo-3dGRUHORf"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit, Features, Encode ..."
      ],
      "metadata": {
        "id": "ipAsBY3LHPxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FE:\n",
        "    def __init__(self):\n",
        "        self.dic_tfid_vectorizer = {}\n",
        "        self.dic_tfid_selected_feature = {}\n",
        "\n",
        "    def get_new_columns(self, df, lags ) :\n",
        "        global lags_all\n",
        "        df = df.join(lags_all, on = ['date_id', 'time_id', 'symbol_id'], how = 'left')\n",
        "        return df\n",
        "\n",
        "    def encoders_fit(self, df) :\n",
        "        ### ONE HOT ENCODER FIT\n",
        "        for col in CFG.cols_onehot :\n",
        "            if col not in cols: cols[col] = dotdict(dict)\n",
        "            cols[col].one_hot_encoder = list(df[col].unique(maintain_order = True))\n",
        "\n",
        "    def encoders_transform(self, df):\n",
        "        ### FIT Cat size / for nn embeding\n",
        "        for col in CFG.categoricals :\n",
        "            if col not in cols: cols[col] = dotdict(dict)\n",
        "            serie = df[col].fill_null('nan')\n",
        "            l_uniques = list(serie.unique(maintain_order = True))\n",
        "            cols[col].cat_size = int(len(l_uniques) + 1)\n",
        "            cols[col].cat_emb = int(np.ceil( np.sqrt(cols[col].cat_size + 1)))\n",
        "\n",
        "        ### ONE HOT ENCODER TRANSFORM\n",
        "        for i, col in enumerate(CFG.cols_onehot) :\n",
        "            for unique in cols[col].one_hot_encoder:\n",
        "                df = df.with_columns((df[col] == unique).cast(pl.Int8).alias(f'ofe_{col}_{i}'))\n",
        "        return df\n",
        "\n",
        "    def feature_engineering(self, df) :\n",
        "        return df\n",
        "\n",
        "    def scaler_fit(self, df):\n",
        "        cols.numercials_means = df[cols.numericals].mean().to_dicts()[0]\n",
        "        cols.numercials_std = df[cols.numericals].std().to_dicts()[0]\n",
        "\n",
        "    def scaler_transform(self, df):\n",
        "        for col in cols.numericals:\n",
        "            df = df.with_columns( (pl.col(col) - cols.numercials_means[col]) / cols.numercials_std[col])\n",
        "        return df\n",
        "\n",
        "    def clean(self, df):\n",
        "        ## DROP\n",
        "        df = df.drop([col for col in cols.drop if col in df.columns])\n",
        "\n",
        "        ## FILL / CAST\n",
        "        if len( CFG.categoricals ) > 0 : df[cols.categoricals] = df[cols.categoricals].fill_null('nan')\n",
        "        df = df.with_columns([pl.col(col).cast(pl.String).cast(pl.Categorical) for col in CFG.categoricals if col in df.columns]) #\n",
        "        for col in cols.numericals:\n",
        "            df = pl.DataFrame(df).with_columns( pl.col(col).fill_null(strategy = 'mean') )\n",
        "        # for col in cols.numericals:\n",
        "        #     if col in df.columns:\n",
        "        #         df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
        "\n",
        "        ##PANDA\n",
        "        df = df.to_pandas()\n",
        "        return df"
      ],
      "metadata": {
        "id": "iFi8c0TaHRqu"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = dotdict(dict)\n",
        "\n",
        "## Data Pipeline\n",
        "print(f'Shape train: {train.shape}')\n",
        "fe = FE()\n",
        "train = fe.get_new_columns(train, lags)\n",
        "\n",
        "fe.encoders_fit(train)\n",
        "print(f'Shape train: {train.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9byK1T5HS83",
        "outputId": "a8163927-da9e-4e39-d9ae-df32350dbbf1"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape train: (415272, 84)\n",
            "Shape train: (415272, 93)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Folds Creation"
      ],
      "metadata": {
        "id": "qce65rjwHU1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class fold():\n",
        "    ## Kfold done before concat with df_duplicated\n",
        "    def prepare(self, df) :\n",
        "        date_id = df['date_id'].to_pandas()\n",
        "        uniques = list(date_id.unique())\n",
        "        df_folds = pd.DataFrame(date_id)\n",
        "\n",
        "        plt.figure(figsize=(20,5))\n",
        "        plt.legend('',frameon=False)\n",
        "        self.folds = {}\n",
        "        if CFG.fold_name == 'time_serie_split' :\n",
        "          for fold in range(CFG.fold_n) :\n",
        "              split = int(len(uniques) * CFG.fold_train_test_split)\n",
        "              train_dates = uniques[:split]\n",
        "              valid_dates = uniques[split:]\n",
        "              train_index = list(date_id[date_id.isin(train_dates)].index)\n",
        "              valid_index = list(date_id[date_id.isin(valid_dates)].index)\n",
        "              self.folds[fold] = (train_index, valid_index)\n",
        "              df_folds.loc[train_index, fold] = 'train'\n",
        "              df_folds.loc[valid_index, fold] = 'valid'\n",
        "              uniques = train_dates\n",
        "              df_folds['fold'] = fold\n",
        "              ax = sns.lineplot(df_folds[['date_id','fold', fold]].dropna(subset=fold), x='date_id', y = 'fold', hue = fold, linewidth = 30)\n",
        "              ax.get_legend().remove()\n",
        "          plt.show()\n",
        "\n",
        "        if CFG.fold_name == 'blocked_time_serie_split' :\n",
        "          split = int(len(uniques) / CFG.fold_n) + 1\n",
        "          for fold in range(CFG.fold_n) :\n",
        "            fold_l_date_id = uniques[split * fold : split * (fold + 1)]\n",
        "            fold_index= list(date_id[date_id.isin(fold_l_date_id)].index)\n",
        "\n",
        "            train_index = fold_index[:int(len(fold_index) * CFG.fold_train_test_split)]\n",
        "            valid_index = fold_index[int(len(fold_index) * CFG.fold_train_test_split):]\n",
        "            self.folds[fold] = (train_index, valid_index)\n",
        "            df_folds.loc[train_index, fold] = 'train'\n",
        "            df_folds.loc[valid_index, fold] = 'valid'\n",
        "            df_folds['fold'] = fold\n",
        "            ax = sns.lineplot(df_folds[['date_id','fold', fold]].dropna(subset=fold), x='date_id', y = 'fold', hue = fold, linewidth = 30)\n",
        "            ax.get_legend().remove()\n",
        "          plt.show()\n",
        "        return df\n",
        "\n",
        "    def get_index(self, fold) :\n",
        "        return self.folds[fold]\n",
        "\n",
        "fld = fold()\n",
        "print(f'Shape train: {train.shape}')\n",
        "train = fld.prepare(train)\n",
        "print(f'Shape train: {train.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "pVGhMDNeHUFX",
        "outputId": "e25c60d4-6997-4a48-e3ef-e1a6c9e7d99e"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape train: (415272, 93)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape train: (415272, 93)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform and Feature Engineering"
      ],
      "metadata": {
        "id": "EaLo7Ab9HYl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape train: {train.shape}')\n",
        "train = fe.encoders_transform(train)\n",
        "train = fe.feature_engineering(train)\n",
        "print(f'Shape train: {train.shape}')\n",
        "train[CFG.categoricals].head(1)\n",
        "train.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "0VSNgog5HZVP",
        "outputId": "8c88e9a1-630f-4b5a-ed7d-c1b2b882b806"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape train: (415272, 93)\n",
            "Shape train: (415272, 93)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (1, 93)\n",
              "┌─────────┬─────────┬───────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
              "│ date_id ┆ time_id ┆ symbol_id ┆ weight   ┆ … ┆ responder_ ┆ responder_ ┆ responder_ ┆ responder_ │\n",
              "│ ---     ┆ ---     ┆ ---       ┆ ---      ┆   ┆ 5_lag_1    ┆ 6_lag_1    ┆ 7_lag_1    ┆ 8_lag_1    │\n",
              "│ i16     ┆ i16     ┆ i8        ┆ f32      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
              "│         ┆         ┆           ┆          ┆   ┆ f32        ┆ f32        ┆ f32        ┆ f32        │\n",
              "╞═════════╪═════════╪═══════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
              "│ 1685    ┆ 0       ┆ 0         ┆ 2.919065 ┆ … ┆ -0.236959  ┆ 1.858875   ┆ -0.225995  ┆ -0.354768  │\n",
              "└─────────┴─────────┴───────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 93)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>&hellip;</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_6</th><th>responder_0_lag_1</th><th>responder_1_lag_1</th><th>responder_2_lag_1</th><th>responder_3_lag_1</th><th>responder_4_lag_1</th><th>responder_5_lag_1</th><th>responder_6_lag_1</th><th>responder_7_lag_1</th><th>responder_8_lag_1</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>1685</td><td>0</td><td>0</td><td>2.919065</td><td>3.255355</td><td>1.48419</td><td>3.444162</td><td>2.822976</td><td>-2.899372</td><td>1.371922</td><td>0.225877</td><td>0.905985</td><td>-0.272986</td><td>11</td><td>7</td><td>76</td><td>-0.71329</td><td>0.795044</td><td>-0.448021</td><td>null</td><td>-0.742601</td><td>null</td><td>-1.127423</td><td>-1.590805</td><td>0.923534</td><td>-0.144347</td><td>1.594534</td><td>0.277505</td><td>1.600862</td><td>1.150071</td><td>1.095508</td><td>1.193035</td><td>0.790825</td><td>-0.903535</td><td>-0.905721</td><td>-0.146948</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>-1.715802</td><td>null</td><td>-2.316973</td><td>0.579623</td><td>null</td><td>-0.491265</td><td>-0.051191</td><td>-0.040133</td><td>-0.288024</td><td>-0.340605</td><td>-0.531377</td><td>-1.626934</td><td>-2.299252</td><td>-0.825951</td><td>0.86093</td><td>-0.201352</td><td>-1.19664</td><td>0.281988</td><td>-0.426263</td><td>null</td><td>null</td><td>0.982125</td><td>0.939474</td><td>0.005379</td><td>0.047556</td><td>-1.72867</td><td>-0.824719</td><td>-0.378881</td><td>-0.454471</td><td>0.810804</td><td>-0.500948</td><td>-0.236959</td><td>1.858875</td><td>-0.225995</td><td>-0.354768</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Columns Selection"
      ],
      "metadata": {
        "id": "Z22Hou51IK5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols.drop = copy.deepcopy(CFG.drop)\n",
        "# cols_onehot\n",
        "cols.drop += CFG.cols_onehot\n",
        "# cols_percentages_to_drop\n",
        "# cols_percentages_to_drop = [col for col in train.columns if train[col].value_counts(normalize = True).max()['proportion'].item() > 0.99]\n",
        "# print('cols_percentages_to_drop : ', cols_percentages_to_drop)\n",
        "# cols.drop += cols_percentages_to_drop\n",
        "cols.drop = list(dict.fromkeys(cols.drop)) #removing duplicates\n",
        "\n",
        "cols.categoricals = list(dict.fromkeys(copy.deepcopy(CFG.categoricals)))\n",
        "### Priotity to CAT cols => if col in cat it will not be dropped\n",
        "cols.drop = [col for col in cols.drop if col not in cols.categoricals]\n",
        "### Drop categoricals col which are one hot encoded\n",
        "cols.categoricals = [col for col in cols.categoricals if col not in CFG.cols_onehot]\n",
        "\n",
        "########################################################################################################## Keep , CFG.col_weight in train\n",
        "cols.numericals = [col for col in train.columns if (col not in cols.categoricals + cols.drop + [CFG.col_target] and train[col].dtype.is_numeric())]\n",
        "cols.numericals = list(dict.fromkeys(cols.numericals))\n",
        "# double_check_cols = [col for col in train.columns if col not in cols.categoricals + cols.drop + cols.numericals + [CFG.col_target]]\n",
        "# cols.drop +=  double_check_cols\n",
        "# print(f\"double_check_cols : {double_check_cols}\")\n",
        "\n",
        "cols.drop = list(dict.fromkeys(cols.drop)) #removing duplicates\n",
        "print(f\"len(drop) : {len(cols.drop)}\")\n",
        "print(cols.drop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJzRFZtdH2UG",
        "outputId": "dcb461e2-dad8-4b60-9ee7-2dae9e12c811"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(drop) : 2\n",
            "['date_id', 'time_id']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols.lgbm = dotdict(dict)\n",
        "cols.catboost = dotdict(dict)\n",
        "cols.xgboost = dotdict(dict)\n",
        "cols.nn = dotdict(dict)\n",
        "\n",
        "cols.lgbm.drop = copy.deepcopy(cols.drop)\n",
        "cols.catboost.drop = copy.deepcopy(cols.drop)\n",
        "cols.xgboost.drop = copy.deepcopy(cols.drop)\n",
        "cols.nn.drop = copy.deepcopy(cols.drop)\n",
        "\n",
        "############### ADD SPECIFIC drops per models\n",
        "cols.lgbm.drop = list(dict.fromkeys(cols.lgbm.drop))\n",
        "cols.catboost.drop = list(dict.fromkeys(cols.catboost.drop))\n",
        "cols.xgboost.drop = list(dict.fromkeys(cols.xgboost.drop))\n",
        "cols.nn.drop = list(dict.fromkeys(cols.nn.drop))\n",
        "###############\n",
        "\n",
        "cols.lgbm.features = list(dict.fromkeys([col for col in cols.numericals + cols.categoricals if col not in cols.lgbm.drop]))\n",
        "cols.catboost.features  = list(dict.fromkeys([col for col in cols.numericals + cols.categoricals if col not in cols.catboost.drop]))\n",
        "cols.xgboost.features = list(dict.fromkeys([col for col in cols.numericals + cols.categoricals if col not in cols.xgboost.drop]))\n",
        "cols.nn.features = list(dict.fromkeys([col for col in cols.numericals + cols.categoricals if col not in cols.nn.drop]))\n",
        "\n",
        "cols.lgbm.categoricals = list(dict.fromkeys([col for col in cols.categoricals if col not in cols.lgbm.drop]))\n",
        "cols.catboost.categoricals = list(dict.fromkeys([col for col in cols.categoricals if col not in cols.catboost.drop]))\n",
        "cols.xgboost.categoricals = list(dict.fromkeys([col for col in cols.categoricals if col not in cols.xgboost.drop]))\n",
        "cols.nn.categoricals = list(dict.fromkeys([col for col in cols.categoricals if col not in cols.nn.drop]))\n",
        "\n",
        "cols.lgbm.numericals = list(dict.fromkeys([col for col in cols.numericals if col not in cols.lgbm.drop]))\n",
        "cols.catboost.numericals = list(dict.fromkeys([col for col in cols.numericals if col not in cols.catboost.drop]))\n",
        "cols.xgboost.numericals = list(dict.fromkeys([col for col in cols.numericals if col not in cols.xgboost.drop]))\n",
        "cols.nn.numericals  = list(dict.fromkeys([col for col in cols.numericals if col not in cols.nn.drop]))\n",
        "\n",
        "json.dump(cols, open(CFG.save_path + 'cols.json', 'w'))\n",
        "print('*' * 70)\n",
        "print(f\"number categoricals cols : {len(cols.categoricals)}, number numericals cols : {len(cols.numericals)}, number drop cols : {len(cols.drop)}, number target : 1\")\n",
        "print(f\"total = {len(cols.categoricals + cols.numericals + cols.drop + [CFG.col_target] + [CFG.col_weight])} == {train.shape[1]} : train.shape\")\n",
        "print(f\"cols categoricals : {cols.categoricals}\")\n",
        "print(f\"cols numericals : {cols.numericals}\")\n",
        "print(f\"debug : {[col for col in cols.categoricals + cols.numericals + cols.drop if col not in train.columns]}\")\n",
        "\n",
        "print('*' * 70)\n",
        "print(f\"len(cols.lgbm.drop) :{len(cols.lgbm.drop)}\")\n",
        "print(f\"len(cols.catboost.drop) :{len(cols.catboost.drop)}\")\n",
        "print(f\"len(cols.xgboost.drop) :{len(cols.xgboost.drop)}\")\n",
        "print(f\"len(cols.nn.drop) :{len(cols.nn.drop)}\")\n",
        "\n",
        "print('*' * 70)\n",
        "print(f\"lgbm.numericals: {len(cols.lgbm.numericals)}, lgbm.categoricals : {len(cols.lgbm.categoricals)}\")\n",
        "print(f\"catboost.numericals : {len(cols.catboost.numericals)}, catboost.categoricals : {len(cols.catboost.categoricals)}\")\n",
        "print(f\"xgboost.numericals : {len(cols.xgboost.numericals)}, xgboost.categoricals : {len(cols.xgboost.categoricals)}\")\n",
        "print(f\"nn.numericals: {len(cols.nn.numericals)}, nn.categoricals : {len(cols.nn.categoricals)}\")\n",
        "\n",
        "print('*' * 70)\n",
        "for name in CFG.l_models :\n",
        "    #if condition returns True, then nothing happens:\n",
        "    assert CFG.col_target not in cols[name].numericals, f'CFG.col_target is in cols.{name}.numericals'\n",
        "    assert CFG.col_target not in cols[name].categoricals, f'CFG.col_target is in cols.{name}.numericals'\n",
        "########################################################################################################## Keep , CFG.col_weight in train\n",
        "    # assert CFG.col_weight not in cols[name].numericals, f'CFG.col_weight is in cols.{name}.numericals'\n",
        "    assert CFG.col_weight not in cols[name].categoricals, f'CFG.col_weight is in cols.{name}.numericals'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCsCkzJzIPJv",
        "outputId": "e8d462db-9de9-446b-cbd0-4cd678ffbd7c"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********************************************************************\n",
            "number categoricals cols : 1, number numericals cols : 89, number drop cols : 2, number target : 1\n",
            "total = 94 == 93 : train.shape\n",
            "cols categoricals : ['symbol_id']\n",
            "cols numericals : ['weight', 'feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06', 'feature_07', 'feature_08', 'feature_09', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54', 'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76', 'feature_77', 'feature_78', 'responder_0_lag_1', 'responder_1_lag_1', 'responder_2_lag_1', 'responder_3_lag_1', 'responder_4_lag_1', 'responder_5_lag_1', 'responder_6_lag_1', 'responder_7_lag_1', 'responder_8_lag_1']\n",
            "debug : []\n",
            "**********************************************************************\n",
            "len(cols.lgbm.drop) :2\n",
            "len(cols.catboost.drop) :2\n",
            "len(cols.xgboost.drop) :2\n",
            "len(cols.nn.drop) :2\n",
            "**********************************************************************\n",
            "lgbm.numericals: 89, lgbm.categoricals : 1\n",
            "catboost.numericals : 89, catboost.categoricals : 1\n",
            "xgboost.numericals : 89, xgboost.categoricals : 1\n",
            "nn.numericals: 89, nn.categoricals : 1\n",
            "**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scale"
      ],
      "metadata": {
        "id": "DNc4lLqnIQlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fe.scaler_fit(train)\n",
        "train = fe.scaler_transform(train)\n",
        "\n",
        "print(f'Shape: {train.shape}')\n",
        "train.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "OOa0uih_IUE8",
        "outputId": "a14efaab-7fb9-449e-aa86-520e0b9fc4f4"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (415272, 93)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (1, 93)\n",
              "┌─────────┬─────────┬───────────┬─────────┬───┬─────────────┬────────────┬────────────┬────────────┐\n",
              "│ date_id ┆ time_id ┆ symbol_id ┆ weight  ┆ … ┆ responder_5 ┆ responder_ ┆ responder_ ┆ responder_ │\n",
              "│ ---     ┆ ---     ┆ ---       ┆ ---     ┆   ┆ _lag_1      ┆ 6_lag_1    ┆ 7_lag_1    ┆ 8_lag_1    │\n",
              "│ i16     ┆ i16     ┆ i8        ┆ f32     ┆   ┆ ---         ┆ ---        ┆ ---        ┆ ---        │\n",
              "│         ┆         ┆           ┆         ┆   ┆ f32         ┆ f32        ┆ f32        ┆ f32        │\n",
              "╞═════════╪═════════╪═══════════╪═════════╪═══╪═════════════╪════════════╪════════════╪════════════╡\n",
              "│ 1685    ┆ 0       ┆ 0         ┆ 0.82294 ┆ … ┆ -0.563527   ┆ 2.595675   ┆ -0.345746  ┆ -0.528307  │\n",
              "└─────────┴─────────┴───────────┴─────────┴───┴─────────────┴────────────┴────────────┴────────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 93)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>&hellip;</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_6</th><th>responder_0_lag_1</th><th>responder_1_lag_1</th><th>responder_2_lag_1</th><th>responder_3_lag_1</th><th>responder_4_lag_1</th><th>responder_5_lag_1</th><th>responder_6_lag_1</th><th>responder_7_lag_1</th><th>responder_8_lag_1</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>1685</td><td>0</td><td>0</td><td>0.82294</td><td>0.762097</td><td>1.770574</td><td>1.186296</td><td>-0.387688</td><td>-3.836275</td><td>1.936603</td><td>0.30236</td><td>1.204998</td><td>-0.826088</td><td>-0.93184</td><td>0.631736</td><td>-0.573034</td><td>-0.970341</td><td>1.482718</td><td>-0.547894</td><td>null</td><td>-1.010588</td><td>null</td><td>-1.143878</td><td>-1.440159</td><td>1.470702</td><td>-0.29334</td><td>1.396492</td><td>0.074068</td><td>0.961303</td><td>1.279175</td><td>0.875883</td><td>1.516127</td><td>1.108803</td><td>-1.513935</td><td>-1.027411</td><td>-0.268226</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>-3.231298</td><td>null</td><td>-2.130095</td><td>0.462959</td><td>null</td><td>-0.672869</td><td>-0.023106</td><td>-1.333784</td><td>1.155757</td><td>-0.111555</td><td>-1.682012</td><td>-1.474781</td><td>-1.758447</td><td>-1.153915</td><td>1.686249</td><td>-0.162494</td><td>-1.804081</td><td>0.648085</td><td>-0.520122</td><td>null</td><td>null</td><td>0.979167</td><td>0.964269</td><td>-0.06562</td><td>-0.002587</td><td>-1.72867</td><td>-2.754978</td><td>-1.157214</td><td>-1.383891</td><td>1.520639</td><td>-0.806372</td><td>-0.563527</td><td>2.595675</td><td>-0.345746</td><td>-0.528307</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean"
      ],
      "metadata": {
        "id": "laRlZRKxIVK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = fe.clean(train)\n",
        "\n",
        "print(f'Shape: {train.shape}')\n",
        "print('Memory usage: {:.2f} MB\\n'.format(train.memory_usage(index=True).sum() / 1024**2))\n",
        "display(train.head(1))\n",
        "display(train[CFG.categoricals].head(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "7U83jpK1IYHp",
        "outputId": "125758a6-78bc-43e2-a8d7-578d25139d22"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (415272, 91)\n",
            "Memory usage: 147.72 MB\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  symbol_id   weight  feature_00  feature_01  feature_02  feature_03  \\\n",
              "0         0  0.82294    0.762097    1.770574    1.186296   -0.387688   \n",
              "\n",
              "   feature_04  feature_05  feature_06  feature_07  feature_08  feature_09  \\\n",
              "0   -3.836275    1.936603     0.30236    1.204998   -0.826088    -0.93184   \n",
              "\n",
              "   feature_10  feature_11  feature_12  feature_13  feature_14    feature_15  \\\n",
              "0    0.631736   -0.573034   -0.970341    1.482718   -0.547894 -5.991742e-08   \n",
              "\n",
              "   feature_16    feature_17  feature_18  feature_19  feature_20  feature_21  \\\n",
              "0   -1.010588 -1.415933e-07   -1.143878   -1.440159    1.470702    -0.29334   \n",
              "\n",
              "   feature_22  feature_23  feature_24  feature_25  feature_26  feature_27  \\\n",
              "0    1.396492    0.074068    0.961303    1.279175    0.875883    1.516127   \n",
              "\n",
              "   feature_28  feature_29  feature_30  feature_31    feature_32    feature_33  \\\n",
              "0    1.108803   -1.513935   -1.027411   -0.268226 -4.021421e-09 -8.618855e-09   \n",
              "\n",
              "   feature_34  feature_35  feature_36  feature_37  feature_38    feature_39  \\\n",
              "0    1.170288    0.844775    2.633046   -0.145712   -1.009499  1.573102e-09   \n",
              "\n",
              "   feature_40    feature_41    feature_42  feature_43    feature_44  \\\n",
              "0    0.318407 -6.782576e-09  1.068760e-09   -2.363009  3.142424e-09   \n",
              "\n",
              "   feature_45  feature_46  feature_47  feature_48  feature_49    feature_50  \\\n",
              "0   -2.077121    1.199921    1.016623   -0.981501    0.263209  1.074043e-08   \n",
              "\n",
              "   feature_51    feature_52    feature_53  feature_54    feature_55  \\\n",
              "0    0.572375  1.668093e-08 -1.181844e-08   -3.231298  9.549209e-09   \n",
              "\n",
              "   feature_56  feature_57    feature_58  feature_59  feature_60  feature_61  \\\n",
              "0   -2.130095    0.462959  5.538106e-09   -0.672869   -0.023106   -1.333784   \n",
              "\n",
              "   feature_62  feature_63  feature_64  feature_65  feature_66  feature_67  \\\n",
              "0    1.155757   -0.111555   -1.682012   -1.474781   -1.758447   -1.153915   \n",
              "\n",
              "   feature_68  feature_69  feature_70  feature_71  feature_72    feature_73  \\\n",
              "0    1.686249   -0.162494   -1.804081    0.648085   -0.520122  7.605900e-09   \n",
              "\n",
              "     feature_74  feature_75  feature_76  feature_77  feature_78  responder_6  \\\n",
              "0  1.386143e-09    0.979167    0.964269    -0.06562   -0.002587     -1.72867   \n",
              "\n",
              "   responder_0_lag_1  responder_1_lag_1  responder_2_lag_1  responder_3_lag_1  \\\n",
              "0          -2.754978          -1.157214          -1.383891           1.520639   \n",
              "\n",
              "   responder_4_lag_1  responder_5_lag_1  responder_6_lag_1  responder_7_lag_1  \\\n",
              "0          -0.806372          -0.563527           2.595675          -0.345746   \n",
              "\n",
              "   responder_8_lag_1  \n",
              "0          -0.528307  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9afb9de8-222e-4b5c-9339-90d084a43f1b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>feature_00</th>\n",
              "      <th>feature_01</th>\n",
              "      <th>feature_02</th>\n",
              "      <th>feature_03</th>\n",
              "      <th>feature_04</th>\n",
              "      <th>feature_05</th>\n",
              "      <th>feature_06</th>\n",
              "      <th>feature_07</th>\n",
              "      <th>feature_08</th>\n",
              "      <th>feature_09</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>feature_11</th>\n",
              "      <th>feature_12</th>\n",
              "      <th>feature_13</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>feature_20</th>\n",
              "      <th>feature_21</th>\n",
              "      <th>feature_22</th>\n",
              "      <th>feature_23</th>\n",
              "      <th>feature_24</th>\n",
              "      <th>feature_25</th>\n",
              "      <th>feature_26</th>\n",
              "      <th>feature_27</th>\n",
              "      <th>feature_28</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>feature_33</th>\n",
              "      <th>feature_34</th>\n",
              "      <th>feature_35</th>\n",
              "      <th>feature_36</th>\n",
              "      <th>feature_37</th>\n",
              "      <th>feature_38</th>\n",
              "      <th>feature_39</th>\n",
              "      <th>feature_40</th>\n",
              "      <th>feature_41</th>\n",
              "      <th>feature_42</th>\n",
              "      <th>feature_43</th>\n",
              "      <th>feature_44</th>\n",
              "      <th>feature_45</th>\n",
              "      <th>feature_46</th>\n",
              "      <th>feature_47</th>\n",
              "      <th>feature_48</th>\n",
              "      <th>feature_49</th>\n",
              "      <th>feature_50</th>\n",
              "      <th>feature_51</th>\n",
              "      <th>feature_52</th>\n",
              "      <th>feature_53</th>\n",
              "      <th>feature_54</th>\n",
              "      <th>feature_55</th>\n",
              "      <th>feature_56</th>\n",
              "      <th>feature_57</th>\n",
              "      <th>feature_58</th>\n",
              "      <th>feature_59</th>\n",
              "      <th>feature_60</th>\n",
              "      <th>feature_61</th>\n",
              "      <th>feature_62</th>\n",
              "      <th>feature_63</th>\n",
              "      <th>feature_64</th>\n",
              "      <th>feature_65</th>\n",
              "      <th>feature_66</th>\n",
              "      <th>feature_67</th>\n",
              "      <th>feature_68</th>\n",
              "      <th>feature_69</th>\n",
              "      <th>feature_70</th>\n",
              "      <th>feature_71</th>\n",
              "      <th>feature_72</th>\n",
              "      <th>feature_73</th>\n",
              "      <th>feature_74</th>\n",
              "      <th>feature_75</th>\n",
              "      <th>feature_76</th>\n",
              "      <th>feature_77</th>\n",
              "      <th>feature_78</th>\n",
              "      <th>responder_6</th>\n",
              "      <th>responder_0_lag_1</th>\n",
              "      <th>responder_1_lag_1</th>\n",
              "      <th>responder_2_lag_1</th>\n",
              "      <th>responder_3_lag_1</th>\n",
              "      <th>responder_4_lag_1</th>\n",
              "      <th>responder_5_lag_1</th>\n",
              "      <th>responder_6_lag_1</th>\n",
              "      <th>responder_7_lag_1</th>\n",
              "      <th>responder_8_lag_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.82294</td>\n",
              "      <td>0.762097</td>\n",
              "      <td>1.770574</td>\n",
              "      <td>1.186296</td>\n",
              "      <td>-0.387688</td>\n",
              "      <td>-3.836275</td>\n",
              "      <td>1.936603</td>\n",
              "      <td>0.30236</td>\n",
              "      <td>1.204998</td>\n",
              "      <td>-0.826088</td>\n",
              "      <td>-0.93184</td>\n",
              "      <td>0.631736</td>\n",
              "      <td>-0.573034</td>\n",
              "      <td>-0.970341</td>\n",
              "      <td>1.482718</td>\n",
              "      <td>-0.547894</td>\n",
              "      <td>-5.991742e-08</td>\n",
              "      <td>-1.010588</td>\n",
              "      <td>-1.415933e-07</td>\n",
              "      <td>-1.143878</td>\n",
              "      <td>-1.440159</td>\n",
              "      <td>1.470702</td>\n",
              "      <td>-0.29334</td>\n",
              "      <td>1.396492</td>\n",
              "      <td>0.074068</td>\n",
              "      <td>0.961303</td>\n",
              "      <td>1.279175</td>\n",
              "      <td>0.875883</td>\n",
              "      <td>1.516127</td>\n",
              "      <td>1.108803</td>\n",
              "      <td>-1.513935</td>\n",
              "      <td>-1.027411</td>\n",
              "      <td>-0.268226</td>\n",
              "      <td>-4.021421e-09</td>\n",
              "      <td>-8.618855e-09</td>\n",
              "      <td>1.170288</td>\n",
              "      <td>0.844775</td>\n",
              "      <td>2.633046</td>\n",
              "      <td>-0.145712</td>\n",
              "      <td>-1.009499</td>\n",
              "      <td>1.573102e-09</td>\n",
              "      <td>0.318407</td>\n",
              "      <td>-6.782576e-09</td>\n",
              "      <td>1.068760e-09</td>\n",
              "      <td>-2.363009</td>\n",
              "      <td>3.142424e-09</td>\n",
              "      <td>-2.077121</td>\n",
              "      <td>1.199921</td>\n",
              "      <td>1.016623</td>\n",
              "      <td>-0.981501</td>\n",
              "      <td>0.263209</td>\n",
              "      <td>1.074043e-08</td>\n",
              "      <td>0.572375</td>\n",
              "      <td>1.668093e-08</td>\n",
              "      <td>-1.181844e-08</td>\n",
              "      <td>-3.231298</td>\n",
              "      <td>9.549209e-09</td>\n",
              "      <td>-2.130095</td>\n",
              "      <td>0.462959</td>\n",
              "      <td>5.538106e-09</td>\n",
              "      <td>-0.672869</td>\n",
              "      <td>-0.023106</td>\n",
              "      <td>-1.333784</td>\n",
              "      <td>1.155757</td>\n",
              "      <td>-0.111555</td>\n",
              "      <td>-1.682012</td>\n",
              "      <td>-1.474781</td>\n",
              "      <td>-1.758447</td>\n",
              "      <td>-1.153915</td>\n",
              "      <td>1.686249</td>\n",
              "      <td>-0.162494</td>\n",
              "      <td>-1.804081</td>\n",
              "      <td>0.648085</td>\n",
              "      <td>-0.520122</td>\n",
              "      <td>7.605900e-09</td>\n",
              "      <td>1.386143e-09</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.964269</td>\n",
              "      <td>-0.06562</td>\n",
              "      <td>-0.002587</td>\n",
              "      <td>-1.72867</td>\n",
              "      <td>-2.754978</td>\n",
              "      <td>-1.157214</td>\n",
              "      <td>-1.383891</td>\n",
              "      <td>1.520639</td>\n",
              "      <td>-0.806372</td>\n",
              "      <td>-0.563527</td>\n",
              "      <td>2.595675</td>\n",
              "      <td>-0.345746</td>\n",
              "      <td>-0.528307</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9afb9de8-222e-4b5c-9339-90d084a43f1b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9afb9de8-222e-4b5c-9339-90d084a43f1b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9afb9de8-222e-4b5c-9339-90d084a43f1b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  symbol_id\n",
              "0         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c62875c-6e5b-4e1d-a875-e427fa208471\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c62875c-6e5b-4e1d-a875-e427fa208471')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c62875c-6e5b-4e1d-a875-e427fa208471 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c62875c-6e5b-4e1d-a875-e427fa208471');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(train[CFG\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"symbol_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new_cols_drop = [col for col in train.columns if train[col].isnull().sum() == train.shape[0]]\n",
        "# print(new_cols_drop)\n",
        "# new_cols_drop = [col for col in train.columns if train[col].isna().sum() == train.shape[0]]\n",
        "# print(new_cols_drop)\n",
        "# new_cols_drop = [col for col in train.columns if train[col].nunique() == 1]\n",
        "# print(new_cols_drop)\n",
        "\n",
        "# duplicateColumnNames = set()\n",
        "# for x in range(train.shape[1]):\n",
        "#     for y in range(x + 1, train.shape[1]):\n",
        "#         if train.iloc[:, x].equals(train.iloc[:, y]):\n",
        "#             duplicateColumnNames.add(train.columns[y])\n",
        "# print(list(duplicateColumnNames))"
      ],
      "metadata": {
        "id": "oWWnZAiMIajp"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "gIY1YQ6xIcp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lrfn(epoch):\n",
        "    if epoch < CFG.nn.lr_rampup:\n",
        "        lr = (CFG.nn.lr_max - CFG.nn.lr_start) / CFG.nn.lr_rampup * epoch + CFG.nn.lr_start\n",
        "    elif epoch < CFG.nn.lr_rampup + CFG.nn.lr_sustain:\n",
        "        lr = CFG.nn.lr_max\n",
        "    else:\n",
        "        lr = CFG.nn.lr_max * CFG.nn.lr_decay **((epoch - CFG.nn.lr_rampup -  CFG.nn.lr_sustain)//2)\n",
        "    return lr\n",
        "\n",
        "rng = [i for i in range(CFG.nn.epochs)]\n",
        "lr_y = [lrfn(x) for x in rng]\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(rng, lr_y, '-o')\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(lr_y[0], max(lr_y), lr_y[-1]))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Learning Rate Schedule\")\n",
        "plt.show()\n",
        "\n",
        "lr_callback = tensorflow.keras.callbacks.LearningRateScheduler(lrfn, verbose = False)\n",
        "es_callback = tensorflow.keras.callbacks.EarlyStopping (monitor = 'val_root_mean_squared_error', patience = 10, verbose = 1, restore_best_weights=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "75oevX2VIeTS",
        "outputId": "18989f24-9033-48ef-fd90-dc6b202e298b"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate schedule: 1e-05 to 1e-05 to 1e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def objective_ls(y_true, y_pred):\n",
        "#     pred = np.apply_along_axis(round_pred, 1, y_pred.reshape(-1,1))\n",
        "#     grad = (y_pred - y_true)\n",
        "#     hess = np.ones(len(y_true))\n",
        "#     return grad, hess\n",
        "\n",
        "# Custom R2 metric for tensorflow\n",
        "def R2_nn(y, y_pred, sample_weight= None):\n",
        "    residual = tf.reduce_sum(tf.square(tf.subtract(y, y_pred)))\n",
        "    # total = tf.reduce_sum(tf.square(tf.subtract(y, tf.reduce_mean(y))))\n",
        "    total = tf.reduce_sum(tf.square(tf.reduce_mean(y)))\n",
        "    r2 = tf.subtract(1.0, tf.div(residual, total))\n",
        "    return r2"
      ],
      "metadata": {
        "id": "ds7iAQpnzWA0"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom R2 metric for XGBoost\n",
        "def r2_xgboost(y_true, y_pred, sample_weight= None):\n",
        "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n",
        "    return -r2\n",
        "\n",
        "# Custom R2 metric for LightGBM\n",
        "def r2_lgb(y_true, y_pred, sample_weight):\n",
        "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n",
        "    return 'r2', r2, True\n",
        "\n",
        "# Custom R2 metric for CatBoost\n",
        "class r2_cbt(object):\n",
        "    def get_final_error(self, error, weight):\n",
        "        return 1 - error / (weight + 1e-38)\n",
        "\n",
        "    def is_max_optimal(self):\n",
        "        return True\n",
        "\n",
        "    def evaluate(self, approxes, target, weight):\n",
        "        assert len(approxes) == 1\n",
        "        assert len(target) == len(approxes[0])\n",
        "        approx = approxes[0]\n",
        "        error_sum = 0.0\n",
        "        weight_sum = 0.0\n",
        "        for i in range(len(approx)):\n",
        "            w = 1.0 if weight is None else weight[i]\n",
        "            weight_sum += w * (target[i] ** 2)\n",
        "            error_sum += w * ((approx[i] - target[i]) ** 2)\n",
        "        return error_sum, weight_sum\n",
        "\n",
        "CFG.lgbm.eval = 'custom'\n",
        "CFG.lgbm.eval_metric = [r2_lgb]\n",
        "CFG.lgbm.metric = [r2_lgb]\n",
        "\n",
        "CFG.catboost.eval_metric = r2_cbt()\n",
        "CFG.xgboost.eval_metric = r2_xgboost\n",
        "CFG.xgboost.disable_default_eval_metric = True\n",
        "# CFG.nn.eval_metric ="
      ],
      "metadata": {
        "id": "t-cSvZVBIfie"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class model(abc.ABC) :\n",
        "    def __init__(self, name, params):\n",
        "        self.name = name\n",
        "        if params is None : self.params = CFG[self.name]\n",
        "        else: self.params = params\n",
        "        print(f'Create model : {self.name}')\n",
        "        print(f'Params: {self.params}')\n",
        "\n",
        "    def load(self, fold) :\n",
        "        self.model = joblib.load(CFG.load_path + f'/{fold}_{self.name}_model')\n",
        "\n",
        "    def save(self, fold) :\n",
        "        joblib.dump(self.model, CFG.save_path + f'{fold}_{self.name}_model')\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def fit(self, fold, X_train, X_valid, y_train, y_valid, w_train = None, w_valid = None) :\n",
        "        pass\n",
        "\n",
        "    def predict(self, df) :\n",
        "        return self.model.predict(df[cols[self.name].features])\n",
        "\n",
        "    def get_feature_importance(self) :\n",
        "        return dict(zip(cols[self.name].features, self.model.feature_importances_))\n",
        "\n",
        "class model_nn(model) :\n",
        "    def __init__(self, name, params):\n",
        "        super().__init__(name, params)\n",
        "        x_input_cats = tensorflow.keras.layers.Input(shape=(len(cols[self.name].categoricals),))\n",
        "        embs = []\n",
        "        for j, col in enumerate(cols.nn.categoricals):\n",
        "            e = tensorflow.keras.layers.Embedding(cols[col].cat_size, cols[col].cat_emb)\n",
        "            x = e(x_input_cats[:,j])\n",
        "            x = tensorflow.keras.layers.Flatten()(x)\n",
        "            embs.append(x)\n",
        "\n",
        "        # NUMERICAL FEATURES\n",
        "        x_input_nums = tensorflow.keras.layers.Input(shape=(len(cols[self.name].numericals),))\n",
        "\n",
        "        # COMBINE\n",
        "        x = tensorflow.keras.layers.Concatenate(axis=-1)(embs+[x_input_nums])\n",
        "        x = tensorflow.keras.layers.Dense(256, activation='relu')(x)\n",
        "        x = tensorflow.keras.layers.Dense(256, activation='relu')(x)\n",
        "        x = tensorflow.keras.layers.Dense(256, activation='relu')(x)\n",
        "        x = tensorflow.keras.layers.Dense(1, activation='linear')(x)\n",
        "\n",
        "        self.model = tensorflow.keras.models.Model(inputs=[x_input_cats, x_input_nums], outputs=x)\n",
        "        self.model.compile(optimizer=tensorflow.keras.optimizers.Adam(0.001),\n",
        "                           loss=\"mean_squared_error\",\n",
        "                           metrics=CFG.nn.metrics)\n",
        "\n",
        "    def fit(self, fold, X_train, X_valid, y_train, y_valid, w_train = None, w_valid = None) :\n",
        "        # train_dataset = tensorflow.data.Dataset.from_tensor_slices(([X_train[cols[self.name].categoricals].astype(int).values, X_train[cols[self.name].numericals].values], y_train, w_train))\n",
        "        # valid_dataset = tensorflow.data.Dataset.from_tensor_slices(([X_valid[cols[self.name].categoricals].astype(int).values, X_valid[cols[self.name].numericals].values], y_valid, w_valid))\n",
        "        # self.model.fit(train_dataset,\n",
        "        #                validation_data = (valid_dataset),\n",
        "        #                callbacks = [lr_callback, es_callback],\n",
        "        #                batch_size=64, epochs=self.params.epochs, verbose=2)\n",
        "        self.model.fit([X_train[cols[self.name].categoricals].astype(int).values, X_train[cols[self.name].numericals].values],\n",
        "                       y_train,\n",
        "                       validation_data = ([X_valid[cols[self.name].categoricals].astype(int).values, X_valid[cols[self.name].numericals].values], y_valid),\n",
        "                       callbacks = [lr_callback, es_callback],\n",
        "                       batch_size=64, epochs=self.params.epochs, verbose=2)\n",
        "\n",
        "    def predict(self, df) :\n",
        "        return self.model.predict([df[cols[self.name].categoricals].astype(int).values, df[cols[self.name].numericals].values], verbose = 0).flatten()\n",
        "\n",
        "    def get_feature_importance(self) :\n",
        "        col_names = []\n",
        "        for col in cols[self.name].categoricals :\n",
        "            for i in range(cols[col].cat_emb) :\n",
        "                col_names.append(f'{col}_{i}')\n",
        "\n",
        "        self = md.models['nn'][0]\n",
        "        for idx, layer in enumerate(self.model.layers) :\n",
        "            if 'concatenate' in layer.name :\n",
        "                break\n",
        "        weights = np.abs(self.model.layers[idx+1].get_weights()[0][:,0])\n",
        "        return dict(zip(col_names + cols[self.name].numericals, weights))\n",
        "\n",
        "class model_lgbm(model) :\n",
        "    def __init__(self, name, params):\n",
        "        super().__init__(name, params)\n",
        "        self.model = lightgbm.LGBMRegressor(**self.params)\n",
        "\n",
        "    def fit(self, fold, X_train, X_valid, y_train, y_valid, w_train = None, w_valid = None) :\n",
        "        self.model.fit(X_train[cols[self.name].features], y_train, w_train,\n",
        "                        eval_metric = self.params.eval_metric,\n",
        "                        eval_set=[(X_valid[cols[self.name].features], y_valid, w_valid)],\n",
        "                        categorical_feature = cols[self.name].categoricals,\n",
        "                        callbacks=[lightgbm.early_stopping(CFG[self.name].early_stopping_rounds, verbose=1),\n",
        "                                  lightgbm.log_evaluation(100)])\n",
        "\n",
        "\n",
        "class model_catboost(model) :\n",
        "    def __init__(self, name, params):\n",
        "        super().__init__(name, params)\n",
        "        self.model = catboost.CatBoostRegressor(**self.params)\n",
        "\n",
        "    def fit(self, fold, X_train, X_valid, y_train, y_valid, w_train = None, w_valid = None) :\n",
        "        validset = catboost.Pool(X_valid[cols[self.name].features], y_valid, weight=w_valid, cat_features= cols[self.name].categoricals)\n",
        "        self.model.fit(X_train[cols[self.name].features], y_train, sample_weight=w_train,\n",
        "                        eval_set=[validset],\n",
        "                        cat_features = cols[self.name].categoricals,\n",
        "                        early_stopping_rounds = CFG[self.name].early_stopping_rounds,\n",
        "                        verbose = 100)\n",
        "\n",
        "class model_xgboost(model) :\n",
        "    def __init__(self, name, params):\n",
        "        super().__init__(name, params)\n",
        "        self.model = xgboost.XGBRegressor(**self.params)\n",
        "        # self.model = xgboost.Booster(**self.params)\n",
        "\n",
        "    def fit(self, fold, X_train, X_valid, y_train, y_valid, w_train = None, w_valid = None) :\n",
        "        dic_fit={}\n",
        "        if w_train is not None : dic_fit['sample_weight']= [w_train]\n",
        "        if w_valid is not None : dic_fit['sample_weight_eval_set']= [w_valid]\n",
        "        self.model.fit(X_train[cols[self.name].features], y_train,\n",
        "                        eval_set=[(X_valid[cols[self.name].features], y_valid)],\n",
        "                        verbose = 100,\n",
        "                        # categorical_feature = cols[self.name].categoricals,\n",
        "                        **dic_fit)\n",
        "        # self.model = xgboost.train\n",
        "\n",
        "## Factory\n",
        "class Model_Factory() :\n",
        "    def get_model(name, params = None):\n",
        "        if name == \"lgbm\":\n",
        "            return model_lgbm(name, params)\n",
        "        elif name == \"catboost\":\n",
        "            return model_catboost(name, params)\n",
        "        elif name == \"nn\":\n",
        "            return model_nn(name, params)\n",
        "        elif name == \"xgboost\":\n",
        "            return model_xgboost(name, params)\n",
        "        else:\n",
        "            raise TypeError(\"Specify a valid name model\")"
      ],
      "metadata": {
        "id": "OUIpklfzIggI"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MD:\n",
        "    def __init__(self):\n",
        "        self.models = collections.defaultdict(list)\n",
        "        self.models_scores = collections.defaultdict(list)\n",
        "        self.oof_preds_scores = []\n",
        "\n",
        "    def get_trained_model(self, name, fold, X_train, X_valid, y_train, y_valid, w_train=None, w_valid=None) :\n",
        "        model = Model_Factory.get_model(name)\n",
        "        if CFG.load :\n",
        "            model.load(fold)\n",
        "        else :\n",
        "            model.fit(fold, X_train, X_valid, y_train, y_valid, w_train, w_valid)\n",
        "        return model\n",
        "\n",
        "    def train(self):\n",
        "        print('*' * 70)\n",
        "        print(f\"{'*' * 30} TRAINING {'*' * 30}\"[:70])\n",
        "        print('*' * 70)\n",
        "        X = train[cols.categoricals + cols.numericals]\n",
        "        y = train[CFG.col_target]\n",
        "        if CFG.col_weight is not None : w = train[CFG.col_weight]\n",
        "\n",
        "        self.oof_preds = np.zeros(len(y))\n",
        "        self.models_preds = np.zeros((len(y), len(CFG.l_models)))\n",
        "        for fold in range(CFG.fold_n):\n",
        "            print(f\"\\033[91m{'*' * 30} FOLD : {fold} {'*' * 30}\\033[0m\"[:70])\n",
        "            train_index, valid_index = fld.get_index(fold)\n",
        "\n",
        "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
        "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "            if CFG.col_weight is not None : w_train, w_valid = w.iloc[train_index], w.iloc[valid_index]\n",
        "            else : w_train, w_valid = None, None\n",
        "\n",
        "            for name in CFG.l_models :\n",
        "                print(f\"\\033[94m{'*' * 30} MODEL : {name} {'*' * 30}\\033[0m\"[:70])\n",
        "                model = self.get_trained_model(name, fold, X_train, X_valid, y_train, y_valid, w_train, w_valid)\n",
        "                model.save(fold)\n",
        "                self.models[name].append(model)\n",
        "                self.models_preds[valid_index, CFG.l_models.index(name)] = pred = model.predict(X_valid)\n",
        "                self.models_scores[name].append(np.sqrt(mean_squared_error(y_valid, pred)))\n",
        "\n",
        "            self.oof_preds[valid_index] = pred = (CFG.weights * self.models_preds[valid_index,:]).sum(axis=1)\n",
        "            self.oof_preds_scores.append(np.sqrt(mean_squared_error(y_valid, pred)))\n",
        "\n",
        "\n",
        "        print('*' * 70)\n",
        "        print(f\"{'*' * 30} OOF RESULTS {'*' * 30}\"[:70])\n",
        "        print('*' * 70)\n",
        "        for i, name in enumerate(CFG.l_models) :\n",
        "            print(f\"{name} OOF scores :{np.sqrt(mean_squared_error(y, self.models_preds[:,i])):.5f}\")\n",
        "            print(f\"{name} mean all scores :{np.mean(self.models_scores[name]):.5f}, std all scores :{np.std(self.models_scores[name]):.5f}, Scores : {self.models_scores[name]}.\")\n",
        "            self.print_feature_importances(name)\n",
        "        print(f\"oof_preds mean scores :{np.mean(self.oof_preds_scores):.5f}, std scores :{np.std(self.oof_preds_scores):.5f}, Scores : {self.oof_preds_scores}.\")\n",
        "\n",
        "    def infer(self, df):\n",
        "        self.models_preds = np.zeros((len(df), len(CFG.l_models)))\n",
        "        for i, name in enumerate(CFG.l_models) :\n",
        "            self.models_preds[:, CFG.l_models.index(name)] = np.mean([model.predict(df[cols[name].features]) for model in self.models[name]], axis = 0)\n",
        "        return (CFG.weights * self.models_preds).sum(axis = 1)\n",
        "\n",
        "    def print_feature_importances(self, name) :\n",
        "        print('*' * 70)\n",
        "        print(f\"{'*' * 30}  FEATURES IMPORTANCE {'*' * 30}\"[:70])\n",
        "        print('*' * 70)\n",
        "        for i, model in enumerate(self.models[name]) :\n",
        "            if i == 0 : feature_importances = np.array(list(model.get_feature_importance().values()))\n",
        "            else : feature_importances += list(model.get_feature_importance().values())\n",
        "        feature_importances = pd.Series(feature_importances, index = list(model.get_feature_importance().keys())).sort_values(ascending=True)\n",
        "\n",
        "        print(f\"{name}_feature_importances les moins importantes: \", list(feature_importances[:20].index))\n",
        "        print(f\"{name}_feature_importances les plus importantes: \", list(feature_importances[-20:].index))\n",
        "        plt.figure(figsize=(20, 8))\n",
        "        sns.barplot(y = feature_importances[-20:].index, x = feature_importances[-20:].values, orient=\"h\")\n",
        "        plt.show()\n",
        "\n",
        "md = MD()"
      ],
      "metadata": {
        "id": "_Q_-oDKPIiYu"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_search_func() :\n",
        "    print(f\"\\033[32m{'*' * 70}\")\n",
        "    print(f\"{'*' * 30} WEIGHT SEARCH {'*' * 30}\"[:70])\n",
        "    print(f\"{'*' * 70} \\033[0m\")\n",
        "    pred_values = md.models_preds\n",
        "    true_values = train[CFG.col_target].values\n",
        "\n",
        "    lr = LinearRegression(fit_intercept = False, positive = True)\n",
        "    lr.fit(pred_values, true_values)\n",
        "\n",
        "    print(f\"CFG.weights before : {CFG.weights}\")\n",
        "    weights = lr.coef_/lr.coef_.sum()\n",
        "    dic_weight = dict((model,weights[i]) for i, model in enumerate(CFG.l_models))\n",
        "    print(f\"CFG.weights after : {weights}\")\n",
        "\n",
        "    pred_values_weighted = (pred_values * weights).sum(axis=1)\n",
        "    pred_values_mean = (pred_values).mean(axis=1)\n",
        "\n",
        "    rmse_score_weighted = np.sqrt(mean_squared_error(pred_values_weighted , true_values))\n",
        "    rmse_score_mean = np.sqrt(mean_squared_error(pred_values_mean, true_values))\n",
        "\n",
        "    print(f\"RMSE MEAN : {rmse_score_mean}\")\n",
        "    print(f\"RMSE WEIGTHED : {rmse_score_weighted}\")\n",
        "    print(f\"dic_weight : {dic_weight}\")\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "To7lmxEkIjrc"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = dotdict(dict)\n",
        "opt.n_trials = 20 if not is_interactive() else 2\n",
        "opt.direction = 'minimize'\n",
        "\n",
        "def run_optimization(objective, n_trials = opt.n_trials , n_jobs = 1):\n",
        "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "    study = optuna.create_study(direction = opt.direction)\n",
        "    study.optimize(objective, n_trials = n_trials, n_jobs = n_jobs, show_progress_bar = False)\n",
        "    return study\n",
        "\n",
        "\n",
        "def optimize(trial):\n",
        "    opt[name] = CFG[name]\n",
        "    opt[name].learning_rate = trial.suggest_float('learning_rate', 1e-2, 2e-1)\n",
        "    opt[name].min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 100) # Alias min_data_per_leaf, min_data, min_child_samples, min_samples_leaf\n",
        "    opt[name].max_depth =  trial.suggest_int('max_depth', 5, 12) # Alias depth\n",
        "    opt[name].num_leaves =  trial.suggest_int('num_leaves', 6, int((2**opt[name].max_depth) * 0.75))\n",
        "    opt[name].subsample =  trial.suggest_float('subsample', 0.05, 1.0) # Alias sub_row, subsample, bagging\n",
        "    opt[name].reg_lambda = trial.suggest_float('reg_lambda', 1e-3, 1.0) # Alias l2_leaf_reg, lambda_l2 , reg_lambda, lambda, l2_regularization\n",
        "\n",
        "    if name == 'lgbm' :\n",
        "        opt[name].colsample_bytree = trial.suggest_float('colsample_bytree', 0.2, 1.0)\n",
        "        opt[name].subsample_freq = trial.suggest_categorical('subsample_freq', [1, 2, 3]) # Alias bagging_freq\n",
        "    if name == 'catboost' :\n",
        "        opt[name].colsample_bylevel = trial.suggest_float('colsample_bylevel', 0.05, 1.0)\n",
        "\n",
        "    model = Model_Factory.get_model(name, opt[name])\n",
        "    model.fit(fold, X_train, X_valid, y_train, y_valid)\n",
        "\n",
        "    pred = model.predict(X_valid)\n",
        "    score = np.sqrt(mean_squared_error(y_valid, pred))\n",
        "\n",
        "    libc.malloc_trim(0)\n",
        "    gc.collect()\n",
        "    return score\n",
        "\n",
        "for name in CFG.l_optuna :\n",
        "    X = train[cols.categoricals + cols.numericals]\n",
        "    y = train[CFG.col_target]\n",
        "\n",
        "    fold = 0\n",
        "    train_index, valid_index = fld.get_index(fold)\n",
        "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
        "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    study = run_optimization(optimize, n_trials=opt.n_trials, n_jobs=1)\n",
        "    best_params = study.best_params\n",
        "\n",
        "    plot_optimization_history(study).show()\n",
        "    plot_param_importances(study).show()\n",
        "    plot_parallel_coordinate(study).show()\n",
        "\n",
        "    print(f'best_params {name} : {best_params}')\n",
        "    print(f'Current Conf : {CFG[name]}')\n",
        "    CFG[name].update(dotdict(**best_params))\n",
        "    print(f'Updated Conf : {CFG[name]}')\n",
        "    json.dump(best_params, open(CFG.save_path + f'{name}_best_params_optuna.json', 'w'))\n",
        "    libc.malloc_trim(0)\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "W5ctpZVMIk4j"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def permutation_importance () :\n",
        "    print(f\"\\033[32m{'*' * 70}\")\n",
        "    print(f\"{'*' * 30} PERMUTATION IMPORTANCE {'*' * 30}\"[:70])\n",
        "    print(f\"{'*' * 70} \\033[0m\")\n",
        "\n",
        "    if is_interactive() : CFG.l_permutation_importance = CFG.l_permutation_importance[:10]\n",
        "    results = dict([(col, 0) for col in CFG.l_permutation_importance])\n",
        "\n",
        "    y = train[CFG.col_target]\n",
        "    X = train[cols.numericals + cols.categoricals]\n",
        "\n",
        "    mse_score = mean_squared_error(md.oof_preds , y)\n",
        "    print(f\"mse_score : {np.sqrt(mse_score)}\")\n",
        "\n",
        "    for fold in range(CFG.fold_n):\n",
        "        print(f\"{'*' * 30} FOLD : {fold} {'*' * 30}\"[:70])\n",
        "        train_index, valid_index = fld.get_index(fold)\n",
        "        tr, va = X.iloc[train_index], X.iloc[valid_index]\n",
        "        y_tr, y_va = y.iloc[train_index], y.iloc[valid_index]\n",
        "\n",
        "        for col in CFG.l_permutation_importance:\n",
        "            save_col = va[col].copy()\n",
        "            va[col] = np.random.permutation(va[col])\n",
        "            if col in cols.categoricals : va[col] = va[col].astype(\"category\")\n",
        "            predicts = []\n",
        "            for name in CFG.l_models :\n",
        "                predicts.append(md.models[name][fold].predict(va[cols[name].features]))\n",
        "            results[col] += (mean_squared_error(np.mean(predicts, axis = 0) ,y_va) - mse_score) / CFG.fold_n\n",
        "            va[col] = save_col\n",
        "\n",
        "    df_perm_impt = pd.DataFrame.from_dict(results, orient='index', columns=['perm_importance'])\n",
        "    df_perm_impt = df_perm_impt.sort_values('perm_importance', ascending=True)\n",
        "    df_perm_impt.to_csv('df_perm_impt.csv')\n",
        "    json.dump(results, open(CFG.save_path + 'result_permutation_importance.json', 'w'))\n",
        "\n",
        "    l_fe_pos_perm = list(df_perm_impt[df_perm_impt.perm_importance > 0].index)\n",
        "    print(f'list {len(l_fe_pos_perm)} features with positives permutation importance : \\n{l_fe_pos_perm}')\n",
        "\n",
        "    l_fe_0_perm = list(df_perm_impt[df_perm_impt.perm_importance == 0].index)\n",
        "    print(f'list {len(l_fe_0_perm)} features with 0 permutation importance :\\n{l_fe_0_perm}')\n",
        "\n",
        "    l_fe_neg_perm = list(df_perm_impt[df_perm_impt.perm_importance < 0].index)\n",
        "    print(f'list {len(l_fe_neg_perm)} features with negative permutation importance :\\n{l_fe_neg_perm}')\n",
        "\n",
        "    abv_zero = df_perm_impt[df_perm_impt.perm_importance > 0]\n",
        "    bel_zero = df_perm_impt[df_perm_impt.perm_importance <= 0]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(20, max(10, int(len(df_perm_impt)/5))))\n",
        "    bars = ax.barh(bel_zero.index, np.round(bel_zero.perm_importance, 5), height = 0.4, color='r')\n",
        "    ax.bar_label(bars)\n",
        "    bars = ax.barh(abv_zero.index, np.round(abv_zero.perm_importance, 5), height = 0.4, color='g')\n",
        "    ax.bar_label(bars)\n",
        "\n",
        "    plt.grid(True)\n",
        "    plt.savefig('perm_impt.png')\n",
        "    plt.show()\n",
        "    del abv_zero, bel_zero, y, X, tr, va, y_tr, y_va, df_perm_impt"
      ],
      "metadata": {
        "id": "H8rhms3bImAB"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CFG.l_permutation_importance = list(dict.fromkeys(CFG.l_permutation_importance))\n",
        "# CFG.l_permutation_importance = list(dict.fromkeys(cols.catboost.features))\n",
        "# CFG.l_permutation_importance = list(dict.fromkeys(cols.categoricals + cols.numericals))\n",
        "# CFG.l_permutation_importance = []"
      ],
      "metadata": {
        "id": "A47UI5f-IoWA"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# name = 'xgboost'\n",
        "# params = CFG[name]\n",
        "# params\n",
        "# X = train[cols.categoricals + cols.numericals]\n",
        "# y = train[CFG.col_target]\n",
        "# if CFG.col_weight is not None : w = train[CFG.col_weight]\n",
        "\n",
        "# for fold in range(CFG.fold_n):\n",
        "#     print(f\"{'*' * 30} FOLD : {fold} {'*' * 30}\"[:70])\n",
        "#     train_index, valid_index = fld.get_index(fold)\n",
        "\n",
        "#     X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
        "#     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "#     if CFG.col_weight is not None : w_train, w_valid = w.iloc[train_index], w.iloc[valid_index]\n",
        "#     else : w_train, w_valid = None, None\n",
        "#     model = xgboost.XGBRegressor(**params)\n",
        "\n",
        "#     dic_fit={}\n",
        "#     if w_train is not None : dic_fit['sample_weight']= [w_train]\n",
        "#     if w_valid is not None : dic_fit['sample_weight_eval_set']= [w_valid]\n",
        "#     model.fit(X_train[cols[name].features], y_train,\n",
        "#                     eval_set=[(X_valid[cols[name].features], y_valid)],\n",
        "#                     verbose = 100,\n",
        "#                     # categorical_feature = cols[self.name].categoricals,\n",
        "#                     **dic_fit)\n",
        "#         # self.model = xgboost.train"
      ],
      "metadata": {
        "id": "qoujfARqadr1"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
        "    global counter\n",
        "\n",
        "    if counter == 0:\n",
        "        libc.malloc_trim(0);\n",
        "        gc.collect();\n",
        "\n",
        "        md.train()\n",
        "        CFG.weights = weight_search_func()\n",
        "        if len(CFG.l_permutation_importance) > 0:\n",
        "            permutation_importance()\n",
        "        counter +=1\n",
        "\n",
        "    if lags is not None:\n",
        "        print('concat', lags.head(1))\n",
        "        lags_all = pl.concat([lags , lags_all])\n",
        "        lags_all = lags_all.unique(['date_id','time_id','symbol_id'])\n",
        "\n",
        "    predictions = test.select('row_id', pl.lit(0.0).alias(CFG.col_target),)\n",
        "    if test['is_scored'][0] :\n",
        "        test = fe.get_new_columns(test, lags)\n",
        "        test = fe.encoders_transform(test)\n",
        "        test = fe.feature_engineering(test)\n",
        "        test = fe.scaler_transform(test)\n",
        "        test = fe.clean(test)\n",
        "\n",
        "        prediction = md.infer(test)\n",
        "        predictions = predictions.with_columns(pl.Series(CFG.col_target, prediction))\n",
        "    # else:\n",
        "        # print( test['date_id'][0])\n",
        "\n",
        "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
        "    assert predictions.columns == ['row_id', CFG.col_target]\n",
        "    assert len(predictions) == len(test)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "J3XMkhhrti2q"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pl.scan_parquet(CFG.data_path + \"train.parquet\").filter((pl.col(\"date_id\") > CFG.date_max-2)).select(['date_id', 'time_id', 'symbol_id', 'weight'] + [f'feature_{x:02d}' for x in range(79)] + [CFG.col_target]).collect()\n",
        "test = test.with_columns(pl.Series(range(len(test))).alias(\"row_id\"))\n",
        "test = test.with_columns(\n",
        "    pl.when((pl.col(\"date_id\") < CFG.date_max))\n",
        "    .then(pl.lit(False))\n",
        "    .otherwise(pl.lit(True)).alias('is_scored')\n",
        ")\n",
        "\n",
        "\n",
        "lags_test = pl.scan_parquet(CFG.data_path + \"train.parquet\").filter((pl.col(\"date_id\") > CFG.date_max-1)).select(['date_id','time_id','symbol_id'] + [f'responder_{x}' for x in range(9)]).collect()\n",
        "lags_test = lags_test.with_columns(pl.col('date_id') + 1)\n",
        "lags_test.columns = lags_all.columns\n",
        "\n",
        "print(train_date_id_min, train_date_id_max)\n",
        "print(lags_all_date_id_min, lags_all_date_id_max)\n",
        "\n",
        "print(test['date_id'].min(), test['date_id'].max())\n",
        "print(lags_test['date_id'].min(), lags_test['date_id'].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwZrI5z9wOX0",
        "outputId": "e027d901-34a3-4060-dc92-34e0123a7d50"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1685 1695\n",
            "1685 1695\n",
            "1694 1698\n",
            "1696 1699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions = []\n",
        "counter = 0\n",
        "\n",
        "for date_id, test_per_date_id in tqdm.tqdm(test.group_by(\"date_id\", maintain_order=True), total=len(test[\"date_id\"].unique()), desc=\"Processing\"):\n",
        "    for time_id, test_per_time_id in test_per_date_id.group_by(\"time_id\", maintain_order=True):\n",
        "        if time_id == 0:\n",
        "            lags = lags_test.filter(pl.col(\"date_id\")==date_id[0])\n",
        "        else:\n",
        "            lags = None\n",
        "        predictions = predict(test_per_time_id, lags)\n",
        "        all_predictions.append(predictions)\n",
        "\n",
        "predictions = pl.concat(all_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "8OGkE-3etsnb",
        "outputId": "ca158e87-e740-425f-88fd-fe142cf253af"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********************************************************************\n",
            "****************************** TRAINING ******************************\n",
            "**********************************************************************\n",
            "\u001b[91m****************************** FOLD : 0 *************************\n",
            "\u001b[94m****************************** MODEL : nn ***********************\n",
            "Create model : nn\n",
            "Params: epochs: 1 | lr: 0.01 | lr_start: 1e-05 | lr_max: 0.01 | lr_rampup: 2 | lr_sustain: 1 | lr_decay: 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|          | 0/5 [00:43<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "EarlyStopping callback received monitor=val_root_mean_squared_error but Keras isn't able to automatically determine whether that metric should be maximized or minimized. Pass `mode='max'` in order to do early stopping based on the highest metric value, or pass `mode='min'` in order to use the lowest value.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-273-30f6826b42d4>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mlags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_per_time_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mall_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-267-d2b638ca8ca4>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(test, lags)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_search_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_permutation_importance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-261-32ede3b07ab3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_models\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\033[94m{'*' * 30} MODEL : {name} {'*' * 30}\\033[0m\"\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-261-32ede3b07ab3>\u001b[0m in \u001b[0;36mget_trained_model\u001b[0;34m(self, name, fold, X_train, X_valid, y_train, y_valid, w_train, w_valid)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-272-9474fa687e6f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, fold, X_train, X_valid, y_train, y_valid, w_train, w_valid)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m#                callbacks = [lr_callback, es_callback],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m#                batch_size=64, epochs=self.params.epochs, verbose=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         self.model.fit([X_train[cols[self.name].categoricals].astype(int).values, X_train[cols[self.name].numericals].values],\n\u001b[0m\u001b[1;32m     59\u001b[0m                        \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                        \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategoricals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/early_stopping.py\u001b[0m in \u001b[0;36m_set_monitor_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0;34mf\"EarlyStopping callback received monitor={self.monitor} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;34m\"but Keras isn't able to automatically determine whether \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: EarlyStopping callback received monitor=val_root_mean_squared_error but Keras isn't able to automatically determine whether that metric should be maximized or minimized. Pass `mode='max'` in order to do early stopping based on the highest metric value, or pass `mode='min'` in order to use the lowest value."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_zero_mean_r2(y_true, y_pred, weights):\n",
        "    numerator = np.sum(weights * (y_true - y_pred)**2)\n",
        "    denominator = np.sum(weights * y_true**2)\n",
        "    r2_score = 1 - numerator / denominator\n",
        "    return r2_score"
      ],
      "metadata": {
        "id": "nh7lhkOz3UDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = test.select(\"responder_6\").to_numpy().reshape(-1)\n",
        "y_pred = predictions.select(\"responder_6\").to_numpy().reshape(-1)\n",
        "weights = test.select(\"weight\").to_numpy().reshape(-1)"
      ],
      "metadata": {
        "id": "_6j_O5E_3T7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_zero_mean_r2(y_true, y_pred, weights)"
      ],
      "metadata": {
        "id": "Frjaj8ky3cP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_pred,y_true,alpha=0.5)\n"
      ],
      "metadata": {
        "id": "XeAXrAhi3agP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}